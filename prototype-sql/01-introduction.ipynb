{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PartiQL query language demonstrator\n",
    "\n",
    "In our discussions about domain-specific languages for particle physics, we agreed that we want the language to be \"declarative,\" to \"specify *what* is to be computed, rather than *how* it is to be computed.\" However, we haven't made many proposals of language features that would achieve this end.\n",
    "\n",
    "PartiQL is a toy language intended to demonstrate several features that would be a radical departure from general-purpose languages, addressing problems specific to particle physics. My intent is to inject ideas into the development of languages intended for physicists, to provide more \"value added\" with respect to conventional programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State of the art\n",
    "\n",
    "Two main classes of languages have been proposed so far: ADL, CutLang, and YAML as an ADL can collectively be called languages with a \"block syntax,\" and RDataFrame, NAIL, [func-adl](https://iris-hep.org/projects/func-adl.html), and my long-defunct [Femtocode](https://github.com/diana-hep/femtocode) can be called \"Spark-like functional languages.\"\n",
    "\n",
    "Except for Femtocode, all of the above were discussed at the [Analysis Description Language Workshop](https://indico.cern.ch/event/769263/timetable/#day-2019-05-06) at Fermilab on May 6‒8, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block languages\n",
    "\n",
    "Block languages have few recognizable programming constructs, providing a high-level feel to analysis code. There are no explicit loops, so a backend system can parallelize or distribute them however necessary. (Decisions about parallelization may still be in the user's control, but not mixed with analysis logic.) Here is an example:\n",
    "\n",
    "```\n",
    "define MR = fMR(megajets)\n",
    "define METl = met + leptonsVeto[0]\n",
    "define Rsql = sqrt(fMTR(megajets, METl) / MR)\n",
    "define Rsq = sqrt(fMTR(megajets, met) / MR)\n",
    "\n",
    "# Boost pre-selection cuts\n",
    "region preselection\n",
    "select AK4jets.size >= 3\n",
    "select AK8jets.size >= 1\n",
    "select MR > 800\n",
    "select Rsq > 0.08\n",
    "```\n",
    "\n",
    "Block constructs like `define` and `region/select` are equivalent to assignment and `if` statements in a general purpose language, but selections with meaningful physics content are named and are potentially searchable/programmatically accessible. Block languages are primarily intended to make analysis code more readable and shareable, not necessarily to make analysis code easier to write. It is not easier to develop an analysis using constructs like `define`, rather than assignment, or `region/select`, rather than `if`, nor is it much harder (apart from more typing).\n",
    "\n",
    "The disadvantage of block languages comes when complex processing is needed—when particles must be combined and looped over to search for solutions to various constraints (colloquially called \"combinatorics\" by physicists). Loops over particle candidates, selecting the best candidate, avoiding overlaps between candidate decays involving many particles, applying constraints like \"same flavor\" without requring a paricular flavor in the result—all of these typical analysis tasks (especially common when an analyis is in development) would significantly complicate the block structure. This kind of logic can be difficult to follow in a general programming language using `=`, `for`, and `if`, but it would get even more difficult if spread out into blocks, pushing more of the analysis description off-screen (due to length). One way out would be to allow analysis descriptions to call external code for the more complex manipulations, but too frequent use of such an \"escape valve\" would undermine the portability and preservation goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional languages\n",
    "\n",
    "Spark-like functional languages also abstract away loops over events, but in a way that doesn't give up general-purpose programming constructs. Replacing a `for` loop with a `map` or `filter` functional, with the body of the `for` loop becoming the function passed to the functional, moves the specification of which events are processed in what order from the `for` arguments into the implementation of the `map` or `filter` functional, which can be externally configured.\n",
    "\n",
    "In RDataFrame and NAIL, the functions passed to functionals are written in a general-purpose programming language: C++ (either as function pointers/references/lambda expressions or as C++ formatted strings that get wrapped as functions). In func-adl and Femtocode, on the other hand, the domain-specific language is self-embedable in the sense that functions passed into functionals are in the same language as the functionals themselves.\n",
    "\n",
    "The advantage of passing functions from a general-purpose language, such as in this example:\n",
    "\n",
    "```c++\n",
    "RDataFrame d(\"myTree\", \"file.root\");\n",
    "auto df = d.Define(\"p\", \"std::array<double, 4> p{px, py, pz}; return p;\")\n",
    "           .Filter(\"double p2 = 0.0; for (auto&& x : p) p2 += x*x; return sqrt(p2) < 10.0;\");\n",
    "```\n",
    "\n",
    "is that there are no restrictions on what can be computed in the loop. The disadvantage is that these functions are opaque to the processing engine: they cannot be further optimized or specialized for particle physics—they can only be executed. Functionals that take functions in a general-purpose language solve a single problem: the large-scale organization of the analysis. As in Vegas, what happens in the loops stays in the loops.\n",
    "\n",
    "I don't mean to minimize the importance of this one problem: it is recognized and important enough that frameworks built by physics collaborations have addressed it in the past. Usually, these object-oriented frameworks defined an abstract processor class with `begin`, `event`, and `end` methods for the physicist-user to override. The framework promised to call the user's `event` method on every event, just as RDataFrame calls the function passed to `Define` or `Filter` on every event. RDataFrame significantly expands the set of functionals (see [cheat sheet](https://root.cern.ch/doc/master/classROOT_1_1RDataFrame.html#cheatsheet)) well beyond `begin`, `event`, and `end`, and NAIL extends them further. However, like object-oriented frameworks, it leaves particle candidate manipulations to the general-purpose language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "func-adl, on the other hand, lets you use the same functionals for subcollections as for collections of events, such as `Select` and `Where` in this example:\n",
    "\n",
    "```python\n",
    "jet_info = (events\n",
    "    .Select(lambda e:\n",
    "        (e.EventInfo('EventInfo'),\n",
    "         e.Jets('AntiKt4EMTopoJets'),\n",
    "         e.Tracks('InDetTrackParticles').Where(lambda t: t.pt() > 1000.0)))\n",
    "    .SelectMany(lambda e1:\n",
    "        e1[1].Select(lambda j:\n",
    "            (e1[0],j,e1[2].Where(lambda t:\n",
    "                DeltaR(t.eta(), t.phi(), j.eta(), j.phi()) < 0.2))))\n",
    "```\n",
    "\n",
    "These functionals, inspired by LINQ, do not make the business of particle combinations any easier than loops in a general-purpose programming language. (Femtocode, as originally conceived, wouldn't have been any better.) At best, the self-embedable feature allows for inner loops to be optimized in conjunction with the outer loops (e.g. vectorized calculations across sets of particles per event)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining block languages with functional\n",
    "\n",
    "I have written three toy languages to try to influence the development of analysis description languages. The first of these, \"Jim's ADL demo,\" ([GitHub](https://nbviewer.jupyter.org/github/jpivarski/analysis-description-language/blob/master/binder/demo.ipynb), [Binder](https://mybinder.org/v2/gh/jpivarski/analysis-description-language/master?filepath=binder%2Fdemo.ipynb), Oct 19, 2018) combined the block language approach with the functional to show that we can combine their strengths.\n",
    "\n",
    "This language used a curly bracket syntax to define cuts as visual blocks, but performed calculations using a functional language, like this:\n",
    "\n",
    "```\n",
    "region \"two muons\": muons.size >= 2\n",
    "{\n",
    "\n",
    "  zmass := muons.distincts                             # make pairs of distinct muons\n",
    "                .map(pair => (pair[0] + pair[1]))      # add the Lorentz vectors\n",
    "                .maxby(zcandidate => zcandidate.pt)    # find the maximum by pt\n",
    "                .mass                                  # but compute and return mass\n",
    "\n",
    "  count \"zmass\" by\n",
    "    regular(60, 0, 120) <- zmass\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "These \"regions\" could be nested to express cut-flows and defined for multiple cuts to compute the same expression for several different cuts (a common physics task).\n",
    "\n",
    "```\n",
    "region \"slices\": true by\n",
    "  regular(5, -5, 5) <- x\n",
    "{\n",
    "  region \"one\":   y > -3\n",
    "         \"two\":   y >  0\n",
    "         \"three\": y >  3\n",
    "  {\n",
    "    count \"counter\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Another basic primitive of particle physics analysis (and *not* general-purpose programming) is a systematic variation—running the same code with different input parameters. These can be blocks (nestable with `region`):\n",
    "\n",
    "```\n",
    "vary\n",
    "  \"central\":    epsilon :=  0       # assignments use := for clarity\n",
    "  \"sigma up\":   epsilon :=  0.5\n",
    "  \"sigma down\": epsilon := -0.5\n",
    "{\n",
    "  count \"histogram\" by\n",
    "    regular(100, -5, 5) <- x + epsilon\n",
    "}\n",
    "```\n",
    "\n",
    "and this nested hierarchy of blocks can be used to define a directory hierarchy of histograms:\n",
    "\n",
    "```python\n",
    "run[\"two muons\", \"zmass\"].plot()\n",
    "\n",
    "run[\"slices\", 2, \"histogram\"].plot()\n",
    "run[\"slices\", 3, \"histogram\"].plot()\n",
    "\n",
    "run[\"central\", \"histogram\"].plot()\n",
    "run[\"sigma up\", \"histogram\"].plot()\n",
    "run[\"sigma down\", \"histogram\"].plot()\n",
    "```\n",
    "\n",
    "The functional language implemented inside of the blocks didn't address the problem of combinatorics (any more than a general-purpose programming language does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
